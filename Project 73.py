# -*- coding: utf-8 -*-
"""Project 73

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RVL4aOsXuzDdgZD1-SdbADX3IGO1EgyM

### Instructions

---

#### Goal of the Project

This project is designed for you to practice and solve the activities that are based on the concepts covered in the following lessons:

 1. Logistic Regression - Univariate Classification I

 2. Logistic Regression - Univariate Classification II

---

#### Getting Started:

1. Click on this link to open the Colab file for this project.

   https://colab.research.google.com/drive/15pzkxDsmwy4Nu5LoRygl8r5ZA7pAT8NH

2. Create a duplicate copy of the Colab file as described below.

  - Click on the **File menu**. A new drop-down list will appear.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/0_file_menu.png' width=500>

  - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/1_create_colab_duplicate_copy.png' width=500>

3. After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_Project73** format.

4. Now, write your code in the prescribed code cells.

---

### Problem Statement

A researcher is interested in assessing how different factors such as GRE (Graduate Record Exam scores), GPA (grade point average), and prestige of the undergraduate institution (RANK) affect admission into graduate school.

Build a Logistic Regression model to help him analyse the impact of GRE scores on admissions.

---

### List of Activities

**Activity 1:** Analysing the Dataset

  
**Activity 2:**  Normalise the Dataset

**Activity 3:**  Calculate the Sigmoid Output

**Activity 4:** Model Prediction

**Activity 5:** Model Evaluation

---

#### Activity 1:  Analysing the Dataset



You are given with the UCI dataset on college admissions. This dataset consists of the following columns:

|Field|Description|
|---:|:---|
|admit|Binary; states whether the student is admitted or not|
|gre|GRE score of the student|
|gpa|GPA of the student on a $4$ point scale|
|rank|Rank of student's postgraduate institution|

Print the first five rows of the dataset.

 **Dataset Link:** https://curriculum.whitehatjr.com/APT+Asset/APT+projects+datasets/binary.csv
"""

# Import the required modules and load the dataset
import pandas as pd
import numpy as np
import random
import seaborn as sns
import matplotlib.pyplot as plt
import math as m

df = pd.read_csv('https://curriculum.whitehatjr.com/APT+Asset/APT+projects+datasets/binary.csv')

# Print the first five rows of Dataframe.
df.head()

"""---

#### Activity 2:  Normalise the Dataset

 Perform the following tasks:

 - Get the descriptive statistics for the `gre` column.

 - Normalise the `gre` column values by calculating their $Z$-scores (or standard scaler).
"""

# Get the descriptive statistics for the 'gre' column.
print(df['gre'].describe())
 # Plot a histogram to show the distribution of values for 'gre' column
plt.figure(figsize = (20,5),dpi = 96)
plt.title("Histogram of  distribution of values for 'gre' column ")
plt.hist(df['gre'], bins = 'sturges',color = 'g',edgecolor = 'black')
plt.grid(axis = 'x')
plt.show()

# Normalise the 'gre' column values using the standard scaler method.
def standard_scaler(series):
  return (series - series.mean()) / series.std()

gre_scaled = standard_scaler(df['gre'])

# Get the descriptive statistics for the normalised 'gre' column.
standard_norm_gre = standard_scaler(df['gre'])
print(standard_norm_gre.describe())

# Plot a histogram to show the distribution of values for normalised 'gre' column
plt.figure(figsize= (20,5),dpi = 96)
plt.title("Histogram of distribution of values for normalised 'gre' column ")
plt.hist(standard_norm_gre, bins = 'sturges',color = 'r' ,edgecolor = 'black')
plt.grid(axis = 'x')
plt.show()

"""---

#### Activity 3:  Calculate the Sigmoid Output

1. Create a sigmoid function.

2.  Calculate the sigmoid output for the scaled (or Normalised) GRE scores.
"""

# Create a sigmoid() function using the above formula.
def sigmoid(x):
    return pd.Series(1/ (1 + np.exp(-x)))

# Calculate the sigmoid output for the scaled (or normalised) GRE scores.
print(sigmoid(standard_norm_gre).head())

# Get the descriptive statistics for the sigmoid output of normalised 'gre'.
print(sigmoid(standard_norm_gre).describe())

"""---

#### Activity 4:  Model Prediction

Consider the threshold probability value of 0.5.

- Create a function that classifies the sigmoid output for the scaled  GRE scores into 0s and 1s using the threshold value of 0.5
"""

# Create a function 'predict()' that takes the sigmoid output and the threshold
# and returns a Pandas series containing the predicted values (0s and 1s) as the output.

def predict(sigmoid_output, threshold):
  y_pred = [1 if i >= threshold else 0 for i in sigmoid_output]
  return pd.Series(y_pred)

# Use the 'predict()' function to classify the 'sigmoid()' function outputs as 0 and 1.
# Consider threshold value of 0.5.
threshold = 0.5
y_pred = predict(sigmoid(standard_norm_gre), threshold)
y_pred

"""---

#### Activity 5:  Model Evaluation

Evaluate the model by calculating the number of false positives and false negatives using a confusion matrix. Also print the classification report for the predicted values.
"""

# Create a confusion matrix for the predicted values.
from sklearn.metrics import classification_report, confusion_matrix
confusion_matrix(df['admit'], y_pred)

# Print the classification report for the predicted values.
print(classification_report(df['admit'], y_pred))

"""----

### Submitting the Project:

1. After finishing the project, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/2_share_button.png' width=500>

2. In the dialog box, make sure that '**Anyone on the Internet with this link can view**' option is selected and then click on the **Copy link** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/3_copy_link.png' width=500>

3. The link of the duplicate copy (named as **YYYY-MM-DD_StudentName_Project73**) of the notebook will get copied.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/4_copy_link_confirmation.png' width=500>

4. Go to your dashboard and click on the **My Projects** option.
   
   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/5_student_dashboard.png' width=800>

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/6_my_projects.png' width=800>

5. Click on the **View Project** button for the project you want to submit.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/7_view_project.png' width=800>

6. Click on the **Submit Project Here** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/8_submit_project.png' width=800>

7. Paste the link to the project file named as **YYYY-MM-DD_StudentName_Project73** in the URL box and then click on the **Submit** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/9_enter_project_url.png' width=800>

---
"""