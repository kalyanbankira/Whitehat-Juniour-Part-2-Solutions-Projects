# -*- coding: utf-8 -*-
"""Copy of Applied Tech. Project 93: Question_copy_v0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hOi7pHWU7hxv6Q7IemogvHRfEor-3nI1

### Instructions

#### Goal of the Project

This project is designed for you to practice and solve the activities that are based on the concepts covered in the lessons:

  * Streamlit Framework I
  * Streamlit Framework II

---

#### Getting Started:

1. Click on this link to open the Colab file for this project.

   https://colab.research.google.com/drive/1eQcZaLXFdYHz1SGbrfIZT_A2PGGPRHKu

2. Create a duplicate copy of the Colab file as described below.

  - Click on the **File menu**. A new drop-down list will appear.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/0_file_menu.png' width=500>

  - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/1_create_colab_duplicate_copy.png' width=500>

3. After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_Project93** format.

4. Now, write your code in the prescribed code cells.

----

#### Problem Statement

In this project, you are going to create a Penguin Species prediction machine learning web app using the Streamlit framework. Also, host the app on the Heroku server.

---

####Context
In this project, you have to create the ML web app to predict the species of Penguin with the given data based on three different models:

- Support Vector Machine
- Logistic Regression
- Random Forest Classifier

You have given the Seaborn dataset on Penguins. This dataset consists of the columns in the table below:

|Field|Description|
|---:|:---|
|species|Categorical; states species of the Penguin.|
|island|Categorical; states home island name for the Penguin in Antarctica.|
|bill_length_mm|Numeric; length measured from the upper edge of the beak (bill) to the base of the skull or the first feathers in mm.|
|bill_depth_mm|Numeric; depth measure from the lower edge of the beak to the upper edge in mm.|
|flipper_length_mm|Numeric; length of the fin of the Penguin in mm.|
|body_mass_g|Numeric; body mass of the Penguin in grams.|
|sex|Categorical; gender of the Penguin.|


 **Dataset Link:** https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/penguin.csv

**Dataset Credits:** Python Seaborn Package

https://github.com/allisonhorst/palmerpenguins

**Citation**

```
Allison Marie Horst, Alison Presmanes Hill, & Kristen B Gorman. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data.

```

### List of Activities

**Activity 1:** Create Python File for the ML Web App
  
**Activity 2:** Predict the Species of Penguin

**Activity 3:** Design the ML Web App

**Activity 4:** Deploy the ML Web App on Heroku Server

---

####Activity 1: Create Python File for the ML Web App


In this activity, you have to create a Python file `penguin_app.py` in Sublime editor and save it in the `Python_scripts` folder.

Copy the code given below in the `penguin_app.py` file. You are already aware of this code which creates areate a function that will accept the model  penguin classification model using SVM, Logistic Regression, Random Forest Classification.

**Note:** Do not run the code shown below. It will throw an error.
"""

# Open Sublime text editor, create a new Python file, copy the following code in it and save it as 'penguin_app.py'.

# Importing the necessary libraries.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Load the DataFrame
csv_file = 'penguin.csv'
df = pd.read_csv(csv_file)

# Display the first five rows of the DataFrame
df.head()

# Drop the NAN values
df = df.dropna()

# Add numeric column 'label' to resemble non numeric column 'species'
df['label'] = df['species'].map({'Adelie': 0, 'Chinstrap': 1, 'Gentoo':2})


# Convert the non-numeric column 'sex' to numeric in the DataFrame
df['sex'] = df['sex'].map({'Male':0,'Female':1})

# Convert the non-numeric column 'island' to numeric in the DataFrame
df['island'] = df['island'].map({'Biscoe': 0, 'Dream': 1, 'Torgersen':2})


# Create X and y variables
X = df[['island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]
y = df['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)


# Build a SVC model using the 'sklearn' module.
svc_model = SVC(kernel = 'linear')
svc_model.fit(X_train, y_train)
svc_score = svc_model.score(X_train, y_train)

# Build a LogisticRegression model using the 'sklearn' module.
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg_score = log_reg.score(X_train, y_train)

# Build a RandomForestClassifier model using the 'sklearn' module.
rf_clf = RandomForestClassifier(n_jobs = -1)
rf_clf.fit(X_train, y_train)
rf_clf_score = rf_clf.score(X_train, y_train)

"""**After this step, the Python file should be created on the local system.**

----

####Activity 2: Predict the Species of Penguin


In this activity, you have to create a function that will accept the classification model object as well as features as input and returns the species of Penguin  as output based on the models trained above.

**Steps:**
1. Create a function `prediction()` that takes the following inputs:
  - `model` (It holds the classification algorithm object chosen by a user)
  - `island`
  - `bill_length_mm`
  - `bill_depth_mm`
  - `flipper_length_mm`
  - `body_mass_g`
  - `sex`

2. Create logic for the `prediction()` function such that:

  - You can call the `predict()` function for classification based on the `model` object.
   
  - Return the Penguin Species - `'Adelie'`, `'Chinstrap'`, `'Gentoo'` based on the output of the `predict()` function

        
   
  - Extract the integer value using the indexing method i.e. `array_name[0]`.

  - Return the name of the species by checking the value of the `species` variable.
"""

# Create a function that accepts 'model', island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g' and 'sex' as inputs and returns the species name.
@st.cache()
def prediction(model, island, bill_length_mm, bill_depth_mm,flipper_length_mm,body_mass_g,sex):
	species = model.predict([[island, bill_length_mm, bill_depth_mm,flipper_length_mm,body_mass_g,sex]])
	species = species[0]
	if species == 0:
		return 'Adelie'
	elif species == 1:
		return 'Chinstrap'
	else
		return 'Gentoo'

"""**Note:** Perform the above tasks in the `penguin_app.py` Python file in **Sublime editor** and run your code using command prompt or terminal. Once you get the desired output, write the code in the code section given above.

**After this activity, the classification Models should be trained for prediction of Penguin Species**

---

####Activity 3: Design the ML Web App

In this activity, you have to design the User Interface of the web app to take the input from users.

**Steps:**

1. Add the title to the app.

2. Add four sliders in the sidebar to select the numeric feature input values `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g`. Store the current value of these slider widgets in different variables.

  **Note:** The minimum and maximum values for these sliders would be the corresponding minimum and maximum values of that particular feature.

3. Add two select boxes in the sidebar to select the categorical feature input values `sex` and `island`. Store the current values of these select boxes in different variables.  Convert the categorical values to numeric.

4. Add a select box in the sidebar to select the three classifiers. Store the current value of the select box in a variable.

5. Add a button in the sidebar to predict the species of Penguin based on the input classifier selected by the user.

6. Print the predicted species name and accuracy score on the screen.
"""

# Design the App
st.title('Penguin species prediction app')

bill_length_input = st.sidebar.slider('bill length(in mm)', float(df['bill_length_mm'].min()), float(df['bill_length_mm'].max()))
bill_depth_input = st.sidebar.slider('bill depth(in mm)', float(df['bill_depth_mm'].min()), float(df['bill_depth_mm'].max()))
flipper_length_input = st.sidebar.slider('flipper length(in mm)', float(df['flipper_length_mm'].min()), float(df['flipper_length_mm'].max()))
body_mass_input = st.sidebar.slider('body mass(in g)', float(df['body_mass_g'].min()), float(df['body_mass_g'].max()))



sex = st.sidebar.selectbox('Gender', ('Male', 'Female'))

if 'sex' == 'Male' :
	sex = 0
else :
	sex = 1


isl = st.sidebar.selectbox('Island', ('Biscoe', 'Dream', 'Torgersen'))

if 'isl' == 'Biscoe' :
	isl = 0
elif 'isl' == 'Dream' :
  isl = 1
else :
  isl = 2

classifier = st.sidebar.selectbox('Classifier', ('Support Vector Classification', 'Random Forest Classifier', 'Logistic Regression'))


if st.sidebar.button('Predict') :
  if classifier == 'Support Vector Classification' :
    species_type= prediction(svc_model, isl, bill_length_input , bill_depth_input, flipper_length_input, body_mass_input, sex)
    accuracy = svc_score

  elif classifier == 'Random Forest Classifier' :
    species_type=prediction(rf_clf, isl, bill_length_input, bill_depth_input, flipper_length_input, body_mass_input, sex)
    accuracy = rf_clf_score

  else :
    species_type=prediction(log_reg, isl, bill_length_input, bill_depth_input, flipper_length_input, body_mass_input, sex)
    accuracy = log_reg_score

  st.write('The type of the species is ', species_type)
  st.write('Acurracy', accuracy)

"""**Note:** Perform the tasks in `penguin_app.py` Python file in **Sublime editor** and run your code using command prompt or terminal. Once you get the desired output, write the code in the code section given above

**After this activity, the ML web app should be ready for deployment.**

---

####Activity 4: Deploy the ML Web App on Heroku

In this activity, you have to deploy the web app on a Heroku server.

**Steps: *(learned in "Activity 1: Streamlit Web App Deployment on Heroku" of "Streamlit II" lesson)*.**

1. Login to GitHub. Create a new Github repository - https://github.com/

2. Upload the following files:
  - Procfile (Procfile)
  - CSV file with Data (penguin.csv)
  - Python file with application code (penguin_app.py)
  - Requirements file (requirement.txt)
  - Setup shell file (setup.sh)

  **Note:**

  **A.** You can download the last two prerequisite file from [here](https://drive.google.com/drive/folders/1OlvOgeLxTudorgAEj_u3pdjhT-V0MF3H?usp=sharing) and the Procfile for this application from [here](https://drive.google.com/file/d/1OJ-0ELAyeH_m-yXN179_4kle4VPg0yIa/view?usp=sharing)

  **B.** After downloading the Procfile, remove its extension `.txt` so that it is not considered as a text file  when uploaded to GitHub.

3. Login to Heroku. Go the Dashboard - https://dashboard.heroku.com/apps

  - Click on new on top left.
  - Click on **Create new app** button.
  - Enter the App name.
  - Click on **Create App** button.
  - Click on **Connect to GitHub** button.
  - Search for a repository to connect.
  - Click on **Connect** button beside the required repository.
  - Verify `the branch to deploy` option has the `main` value selected.
  - Click on the **Deploy Branch** button.
  - Copy the URL for the web app and open it in New Window.

---

**Submissions: *(You have to add the submission in place of the blanks)* .**

**1.** Add the GitHub Repository URL below:

  The URL for the GitHub Repo is: _____________________________

**2.** Add the ML Web App URL below:

  Peguin Species Prediction app: _____________________________

---

### Submitting the Project:

1. After finishing the project, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/2_share_button.png' width=500>

2. In the dialog box, make sure that '**Anyone on the Internet with this link can view**' option is selected and then click on the **Copy link** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/3_copy_link.png' width=500>

3. The link of the duplicate copy (named as **YYYY-MM-DD_StudentName_Project93**) of the notebook will get copied.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/4_copy_link_confirmation.png' width=500>

4. Go to your dashboard and click on the **My Projects** option.
   
   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/5_student_dashboard.png' width=800>

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/6_my_projects.png' width=800>

5. Click on the **View Project** button for the project you want to submit.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/7_view_project.png' width=800>

6. Click on the **Submit Project Here** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/8_submit_project.png' width=800>

7. Paste the link to the project file named as **YYYY-MM-DD_StudentName_Project93** in the URL box and then click on the **Submit** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/9_enter_project_url.png' width=800>

---
"""