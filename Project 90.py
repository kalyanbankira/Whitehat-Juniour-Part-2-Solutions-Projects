# -*- coding: utf-8 -*-
"""project 90.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pShY9gztr5nQgqn5hOe_jbny15xCWzwM

# Capstone Project 18: Olivetti Faces Case-Study

---

## Instructions

### Goal of the Project:

From class 82 to class 90, you learned the following concepts:

 - Support Vector Machines - Introduction
 - Support Vector Machines - Hyperplane Visualisation II
 - Support Vector Machines - MNIST Digits Classification I
 - Support Vector Machines - MNIST Digits Classification II
 - Support Vector Machines - Regression

In this project, you will apply what you have learned in class 82 - 90 to achieve the following goals.

|||
|-|-|
|**Main Goal**|Create a Support Vector Machine classification model to identify the faces in the dataset.
|

---

### Context

Face Recognition, a highly active area in Artificial Intelligence, is used to identify the faces in photos, videos, or real-time. There are various applications of face recognition based on its purpose which can be on a small levels like a Mobile Phone or a high level like a Government Document. Some of them are:

- Authenticate services like face lock, attendance system.

- Management of Data like Census Management or on small level Mobile Phone Photo Gallery Management.

---

#### Getting Started

Follow the steps described below to solve the project:

1. Click on the link provided below to open the Colab file for this project.
   
   https://colab.research.google.com/drive/1nzcoemVcvafgfnSGbMjLx9oAjFKBBv6h

2. Create the duplicate copy of the Colab file. Here are the steps to create the duplicate copy:

    - Click on the **File** menu. A new drop-down list will appear.

      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/0_file_menu.png' width=500>

    - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.

      <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/1_create_colab_duplicate_copy.png' width=500>

     - After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_CapstoneProject18** format.

3. Now, write your code in the prescribed code cells.

---

### Problem Statement

The dataset contains a set of images taken between April 1992 and 1994 at AT&T Laboratories Cambridge.

The data includes ten different images of each of 40 distinct people. The images were taken at a different time and with varying lights, with different facial expression (open/closed eyes, smiling/not smiling) and with/without glasses. All the images were taken against a dark background with the people in an upright, frontal position.


The goal here is to train the SVM classification model to identify the recognise the labels (identifying the people) based on the images.


**Things To Do:**

1. Importing and Analysing the Dataset

2. Visualising the Images

3. Train-Test Split

4. Model Training and Prediction

5. Model Evaluation

----

### Dataset Description

The images are grayscale of size  $64 \times 64$ pixels. Each pixel is stored as a feature, hence we have $64 \times 64 = 4096$ feature columns with values in the interval of $[0, 1]$. Also, there is a target column which has labels from $0$ to $39$ indicating the identity of the people used as subjects. Some of the images of the subjects are:

<center><img src = 'https://s3-whjr-v2-prod-bucket.whjr.online/100a1d64-ab2a-4179-816d-2df298d36d54.png' width = 800></center>

**Dataset Link:** https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces

**Dataset Credits:**
```
AT&T Laboratories Cambridge
```

---

#### Activity 1:  Importing and Analysing the Dataset

In this activity, we have to load the dataset and analyse it.


**Perform the following tasks:**
- Load the feature dataset and target dataset into different DataFrames.

- Verify the number of rows and columns of both DataFrames.

- Merge the target DataFrame into the feature DataFrame and rename the column as a `target`.

- Print the information of the DataFrame and check null values.

- Verify the number of instances for each label.

---

**1.** Start with importing all the required modules:
"""

# Import modules
import pandas as pd
import numpy as np
import matplotlib.pyplot  as plt
import seaborn as sns
# Filter warnings
import warnings
warnings.filterwarnings('ignore')

"""**2.** Create a Pandas DataFrame for the **Feature** dataset using the below link with `header=None`. Print first five rows of the DataFrame:

  **Feature Dataset Link:**  https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_X.csv
"""

# Load the Feature dataset into DataFrame.
feature_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_X.csv',header = None)
feature_df.head()

"""**3.** Create a Pandas DataFrame for the **Target** dataset using the below link with `header=None`. Print first five rows of the DataFrame:

  **Target Dataset Link:**  https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_y.csv
"""

# Load the Target dataset into DataFrame.
target_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_y.csv',header = None)
target_df.head()

"""**4.** Verify the number of rows and columns in both of the DataFrame:"""

# Print the number of rows and columns of both the DataFrame
print(f"Shape of feature datafame : {feature_df.shape}")
print(f"Shape of target datafame :{target_df.shape}")

"""**Q.** Are the number of rows in target and feature DataFrame equal?

**A.** Yes

**Q.** How many columns are there in feature and target DataFrame?

**A.** There are 4096 columns in feature dataframe and 1 column in target dataframe.

---

**5.** Merge the target DataFrame to the feature DataFrame as the last column naming it as the `target` column.

**6.** Print the number of rows and columns of the Feature DataFrame after merging. Print the first five rows of this DataFrame as well:
"""

# Merge the Feature and Target DataFrame
# Add `target` column in Feature DataFrame.
feature_df['target'] = target_df

# Verify the number of rows and columns in Feature DataFrame
print(feature_df.shape)

# Print first five rows
new_df = feature_df
new_df.head()

"""**Q.** How many rows and columns are there in the new merged Feature DataFrame?

**A.** There are 399 rows and 4097 columns are there in the new merged Feature DataFrame.

---

**6.** Print the labels in the target column and their distribution:
"""

# Check the distribution of the labels in the target column.
new_df['target'].value_counts()

"""**Q.** How many labels are there in the target column?

**A.** There are 40 labels in the target column.

**Q.** Which target label has more records?

**A.** All the labels except zero has equal no.of records.

**After performing this activity, you must obtain the DataFrame with feature columns and the target column identified.**

---

#### Activity 2: Visualising the Images

In this activity, you need to visualise exactly one sample image  for all the unique labels by grouping.

**Steps: (Learned in "Lesson 87: Support Vector Machines - MNIST Digits Classification II, Activity 4: Visualising Digits")**

**1.** Create a group object of the DataFrame and store it in a variable.

**2.** Create a Python function that takes the label as input for which one sample image needs to be created and returns the corresponding image as an output. Let's refer to this input value by the `label_in_grouped_df` variable.

**3.** Get a data frame containing the pixel values of all the images for a label (referred to as `label_in_grouped_df`).

**4.** For this label (referred to as `label_in_grouped_df`), get the row number of its first sample in the `df` DataFrame.

**5.** Create a 2D NumPy array of $64 \times 64$ for the pixel values of this sample image for the label.

**6.** Use the NumPy array to create the required image.
"""

# Create a Python function to visualise exactly one sample image of a label that exists in the 'df' DataFrame.
# Create the group object of the DataFrame
grouped_df = new_df.groupby(by='target')

# Define the function to visualise the images
def visual_images(label_in_grouped_df):

  # Get the group for the input label
    img_pix_df =  grouped_df.get_group(label_in_grouped_df)

  # Get the row number of the first instance in the group
    img_pix_row_num = img_pix_df.index.values[0]

  # Get the data of the row number selected
    print(new_df[img_pix_row_num])

  # Reshape the data into a 2D array of 64 x 64.
    image_pixels_array = new_df.iloc[img_pix_row_num,:-1].values.reshape(64,64)

  # Create the image
    plt.figure(figsize=(6,4),dpi= 96)
    plt.title(f'Pixel image of {label_in_grouped_df}')
    plt.imshow(image_pixels_array,cmap='gray', vmin=0, vmax=1)
    plt.show()

"""**7.** After creating the Python function, use a `for` loop to generate numbers from 0 to 39 (including both) and then create one sample image that exists in the `df` data frame corresponding to these labels:

"""

# Call the function to create the images.
for i in range(40):
    visual_images(i)

"""**After this activity, exactly one image of every label should be visualised.**

----

#### Activity 3: Train-Test Split

You need to classify the labels in the `target` variable, using other variables. Thus, the `target` is the target or dependent variable and other columns except `target` are the features or the independent variables.

**1.** Split the dataset into the training set and test set such that the training set contains 70% of the instances and the remaining instances will become the test set.

**2.** Set `random_state = 42`.
"""

# Split the training and testing data
# Import the module
from sklearn.model_selection import train_test_split
# Create the feature and target variables
X = new_df.columns[:-1]
X = new_df[X]
y = new_df['target']
# Split the feature and target arrays
features_train,features_test,target_train,target_test = train_test_split(X,y,test_size= 0.3,random_state = 42)

"""**3.** Print the number of rows and columns in the training and testing set:"""

# Print the shape of all the four variables i.e. 'X_train', 'X_test', 'y_train', and 'y_test'
print(f" Shape of X_train :{features_train.shape}")
print(f" Shape of X_test :{features_test.shape}")
print(f" Shape of y_train :{target_train.shape}")
print(f" Shape of y_test :{target_test.shape}")

"""**After this activity, the feature and target data should be distributed in training and testing data**

---

#### Activity 4: Model Training and Prediction

Implement SVM classification using the `sklearn` module in the following way:

**1.** Deploy the model by importing the `SVC` class.

**2.** Create an object of the `SVC` class and pass `kernel = "linear"` as input to its constructor.

**3.** Call the `fit()` function of the `SVC` class on the object created and pass `X_train` and `y_train` as inputs to the function.

**4.** Call the `score()` function with `X_train` and `y_train` as inputs to check the accuracy score of the model.
"""

# Build a logistic regression model using the 'sklearn' module.
from sklearn.svm import SVC

# 1. Create the SVC model and pass 'kernel=linear' as input.
svc_model = SVC(kernel = 'linear')

# 2. Call the 'fit()' function with 'X_train' and 'y_train' as inputs.
svc_model.fit(features_train,target_train)
# 3. Call the 'score()' function with 'X_train' and 'y_train' as inputs to check the accuracy score of the model.
svc_model.score(features_train,target_train)

"""**5.** Make the predictions on the train set using `predict()` function:"""

# Make predictions on the train dataset by using the 'predict()' function.
target_train_pred = svc_model.predict(features_train)
# Print the occurrence of each label computed in the predictions.
print(pd.Series(target_train_pred).value_counts())

"""**6.** Make predictions on the test dataset by using the `predict()` function:

"""

# Make predictions on the test dataset.
target_test_pred = svc_model.predict(features_test)

# Print the occurrence of each label computed in the predictions.
print(pd.Series(target_test_pred).value_counts())

"""**After this activity, an SVM model should be trained and values of the labels should be predicted for the target columns for multiclass classification.**

----

#### Activity 5: Model Evaluation

**1.** Create a confusion matrix to calculate true positives, false positives, true negatives, and false negatives for the **training dataset** to evaluate the SVC linear model. Store the confusion matrix in a DataFrame.

**2.** Create a heatmap for the training confusion matrix DataFrame:
"""

# Create the confusion matrix heatmap for the training dataset predictions
# Import the module
from sklearn.metrics import classification_report,confusion_matrix

# Create the training confusion matrix DataFrame
train_cm_df = pd.DataFrame(confusion_matrix(target_train,target_train_pred))
# Create the heatmap
plt.figure(figsize=(20,10),dpi = 96)
sns.heatmap(train_cm_df,annot = True)
plt.show()

"""**Hint:** Since there are a lot of labels (40), keep the height of the graph $>=10$

---

**3.** Print the classification report for the training predictions:
"""

# Print the classification report for the training predictions.
print(classification_report(target_train,target_train_pred))

"""**Q.** What is the lowest f1-score? Which label has the lowest f1-score in the training dataset predictions?

**A.** There is no any lowest f1-score other than value 1 in the training dataset predictions.

---

**4.** Create a confusion matrix DataFrame for the **testing dataset** to evaluate the SVC linear model.

**5.** Create a heatmap for the testing confusion matrix DataFrame.
"""

# Create the confusion matrix heatmap for the testing dataset predictions
# Create the testing confusion matrix DataFrame
target_test_df = pd.DataFrame(confusion_matrix(target_test,target_test_pred))
# Create the heatmap
plt.figure(figsize=(20,10),dpi = 96)
sns.heatmap(target_test_df,annot = True)
plt.show()

"""**6.** Print the classification report for the testing predictions:"""

# Print the classification report for the testing predictions.
print(classification_report(target_test,target_test_pred))

"""**Q.** What is the lowest f1-score? Which label has the lowest f1-score in the testing dataset predictions?

**A.** `0.75` is the lowest f1-score .The 39 and 0 label has the lowest f1-score in the testing dataset predictions.

**After this activity, the model should be evaluated for the target columns using the test features set.**

----

### Submitting the Project

Follow the steps described below to submit the project.

1. After finishing the project, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/2_share_button.png' width=500>

2. In the dialog box, click on the **Copy link** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/3_copy_link.png' width=500>


3. The link of the duplicate copy (named as **YYYY-MM-DD_StudentName_CapstoneProject18**) of the notebook will get copied

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/4_copy_link_confirmation.png' width=500>

4. Go to your dashboard and click on the **My Projects** option.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/5_student_dashboard.png' width=800>

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/6_my_projects.png' width=800>

5. Click on the **View Project** button for the project you want to submit.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/7_view_project.png' width=800>

6. Click on the **Submit Project Here** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/8_submit_project.png' width=800>

7. Paste the link to the project file named as **YYYY-MM-DD_StudentName_CapstoneProject18** in the URL box and then click on the **Submit** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/9_enter_project_url.png' width=800>

---
"""