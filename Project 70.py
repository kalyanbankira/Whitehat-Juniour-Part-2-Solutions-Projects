# -*- coding: utf-8 -*-
"""Project 70.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mBxQgeFrprnQnjGqdpahatjGqaHlKs4R

### Instructions

---

#### Goal of the Project

This project is designed for you to practice and solve the activities that are based on the concepts covered in the following lesson:

 1. Multiple linear regression - Introduction
 2. Multicollinearity
 3. Variance Inflation Factor
 4. Car Price Prediction - RFE

---

#### Getting Started:

1. Click on this link to open the Colab file for this project.

    https://colab.research.google.com/drive/1652FnxXEMT1dfXwJ5jVOrY61xG3CO_BG

2. Create a duplicate copy of the Colab file as described below.

  - Click on the **File menu**. A new drop-down list will appear.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/0_file_menu.png' width=500>

  - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/1_create_colab_duplicate_copy.png' width=500>

3. After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_Project70** format.

4. Now, write your code in the prescribed code cells.

---

### Problem Statement

Many of your friends may be worried about their chances of getting admission in their dream university for pursuing MS. So, you decided to help them by building a model which is capable of predicting their chance of getting admission in their dream masters program. This model should also help them in understanding which factors are important in MS admissions and what are the scores required for different tests to have better admission chances.

Build a prediction model using multiple linear regression to predict the likelihood of getting admission and evaluate the accuracy of the model.
If there is multicollinearity in the dataset, apply RFE to eliminate redundant features and validate the selected features using VIF.

---

### List of Activities

**Activity 1:** Analyse the Dataset

**Activity 2:** Find Correlation
  
**Activity 3:** Train-Test Split

**Activity 4:** Train the Model

**Activity 5:** Determine Highly Correlated Features

**Activity 6:** Perform RFE

---

#### Activity 1:  Analyse the Dataset

- Create a Pandas DataFrame for **Admission_Predict** dataset using the below link. This dataset consists of several parameters which are considered important during the application for Masters program:


|Field|Description|
|---:|:---|
|Serial No.|Serial No.|
|GRE Score|GRE Scores ( out of 340 )|
|TOEFL Score|TOEFL Scores ( out of 120 )|
|University Rating|University Rating ( out of 5 )|
|SOP|Statement of Purpose Strength ( out of 5 )|
|LOR|Letter of Recommendation Strength ( out of 5 )|
|CGPA|Undergraduate GPA ( out of 10 )|
|Research|Research Experience ( either 0 or 1 )|
|Chance of Admit|Chance of Admit ( ranging from 0 to 1 )|



  **Dataset Link:** https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/Admission_Predict.csv

- Print the first five rows of the dataset. Check for null values and treat them accordingly.

- Also drop the column `Serial No.` from the dataset as it is of no use for analysis. Check whether the column names contain any trailing and leading spaces. If yes, remove the whitespaces from the column names.

**Hint:** You can use `strip()` and `rename()` functions to remove unwanted whitespaces from the column name and to rename them.
"""

# Import modules
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/Admission_Predict.csv')
# Print first five rows using head() function
df.head()

# Check if there are any null values. If any column has null values, treat them accordingly
df.isnull().sum()

# Get the list of columns of the dataset.
df.columns

# Drop 'Serial No.' column from the DataFrame
df.drop(columns =['Serial No.'],axis = 1, inplace = True)
df.columns

# Remove whitespaces from both ends in the column name if there are any
for i in df.columns:
    df.rename(columns={i: i.strip()}, inplace = True)

# Get list of all the columns after renaming.
df.columns

"""---

#### Activity 2: Find Correlation

We need to predict the value of `Chance of Admit` variable, given other variables. Thus, `Chance of Admit` is the target variable and other columns except `Chance of Admit` are the feature variables.

Find the columns that are highly correlated with the `Chance of Admit` column. For this, calculate the correlation coefficient values between all the columns and then use a heatmap to visualise these correlations.
"""

# Remove whitespaces from both ends in the column name if there are any
for i in df.columns:
    df.rename(columns={i: i.strip()}, inplace = True)

# Get list of all the columns after renaming.
df.columns

"""---

#### Activity 3: Train-Test Split


Split the dataset into training set and test set such that the training set contains 70% of the instances and the remaining instances will become the test set.
"""

# Split the DataFrame into the training and test sets.
from sklearn.model_selection import train_test_split

feature = list(df.columns)
feature.remove('Chance of Admit')

X = df[feature]
y = df['Chance of Admit']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)

"""---

#### Activity 4: Train the Model

Now build a multiple linear regression model using the `statsmodels.api` module.
Also, print the summary of the linear regression model built.
"""

#  Build the linear regression model using all the features
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm

X_train_sm = sm.add_constant(X_train)
lr = sm.OLS(y_train, X_train_sm).fit()
lr.params

# Print the summary of the linear regression report.
print(lr.summary())

"""**Q:** Does the summary report indicate the presence of multicollinearity?

**A:** Yes, the summary report indicate the presence of multicollinearity?

----

#### Activity 5: Determine Highly Correlated Features

Find the moderately to highly correlated features with `Chance of Admit` and the corresponding correlation values.
"""

# Create a Python dictionary storing the moderately to highly correlated features with 'Chance of Admit' and the corresponding correlation values.
major_features = {}
for i in feature:
    coeff = np.corrcoef(df['Chance of Admit'], df[i])[0, 1]
    print(coeff)
    if (coeff >= 0.5 ) or (coeff <= 0.5 ):
        major_features[i] = coeff
print('\n Final Dict: \n')
major_features

"""**Q:** How many features are moderately to highly correlated with `Chance of Admit`?

**A:** 7




"""

# Create a heatmap to visualise the correlation between the above correlated features (if there exists).
plt.figure(figsize=(20,5),dpi = 96)
sns.heatmap(df[major_features.keys()].corr(),annot = True)
plt.show()

"""#### Activity 6: Perform RFE (Recursive Feature Elimination)

1. Choose the number of features that you want to use for RFE (choose 3 to 5 features).
2. Apply RFE using `sklearn.feature_selection` module.
2. Build linear regression model using the best features selected by RFE.
3. Validate the significance of the selected features by calculating their VIF values.
"""

# Use RFE to eliminate few features from the dataset.

from sklearn.linear_model import LinearRegression

# Import RFE

from sklearn.feature_selection import RFE

# RFE with 3-5 features.

lin_reg1 = LinearRegression()
rfe = RFE(lin_reg1, n_features_to_select= 4)

# Fit with selected features.

rfe.fit(X_train[major_features.keys()],y_train)

# Print the 'support_' and 'ranking_' attributes to find out the features selected by RFE
print(major_features.keys())
print(rfe.support_)
print(rfe.ranking_)

# Print the features selected by RFE in the previous step.
rfe_features = X_train[major_features.keys()].columns[rfe.support_]
rfe_features

# Build a linear regression model using the 'statsmodels.api' module having the above features selected by RFE.
# Import the 'statsmodels.api' module.

import statsmodels.api as sm

# Subset the train set such that it contains only the above  selected features.

X_train_rfe = X_train[rfe_features]

# Add the 'const' column to the features set.
X_train_rfe = sm.add_constant(X_train_rfe)

# Fit the model

sm_lin_reg = sm.OLS(y_train, X_train_rfe).fit()

# Print the summary of the linear regression report

print(sm_lin_reg.summary())

# Check for the VIF values of the features selected by RFE above.
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif = pd.DataFrame()
vif['Features'] = X_train_rfe.columns
vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = 'VIF', ascending = False)
vif[1:]

"""**Q:** How many features have VIF values above 10?

**A:** No features have VIF values above 10.

**Q:** What is the $R^2$ value after RFE?

**A:** 0.785

----

### Submitting the Project:

1. After finishing the project, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/2_share_button.png' width=500>

2. In the dialog box, make sure that '**Anyone on the Internet with this link can view**' option is selected and then click on the **Copy link** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/3_copy_link.png' width=500>

3. The link of the duplicate copy (named as **YYYY-MM-DD_StudentName_Project70**) of the notebook will get copied

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/4_copy_link_confirmation.png' width=500>

4. Go to your dashboard and click on the **My Projects** option.
   
   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/5_student_dashboard.png' width=800>

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/6_my_projects.png' width=800>

5. Click on the **View Project** button for the project you want to submit.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/7_view_project.png' width=800>

6. Click on the **Submit Project Here** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/8_submit_project.png' width=800>

7. Paste the link to the project file named as **YYYY-MM-DD_StudentName_Project70** in the URL box and then click on the **Submit** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/9_enter_project_url.png' width=800>

---
"""