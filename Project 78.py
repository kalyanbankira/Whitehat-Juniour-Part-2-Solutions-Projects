# -*- coding: utf-8 -*-
"""project 78 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1utJfvDkmRXXyjAyXDy3yog71X0EEALFK

### Instructions

---

#### Goal of the Project

This project is designed for you to practice and solve the activities that are based on the concepts covered in the Logistic Regression Lessons

---

#### Getting Started:

1. Click on this link to open the Colab file for this project.

     https://colab.research.google.com/drive/1vis2e2aYid986w58hes8KTPxKcZFmFCW
     
2. Create a duplicate copy of the Colab file as described below.

  - Click on the **File menu**. A new drop-down list will appear.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/0_file_menu.png' width=500>

  - Click on the **Save a copy in Drive** option. A duplicate copy will get created. It will open up in the new tab on your web browser.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-0/1_create_colab_duplicate_copy.png' width=500>

3. After creating the duplicate copy of the notebook, please rename it in the **YYYY-MM-DD_StudentName_Project78** format.

4. Now, write your code in the prescribed code cells.

---

### Problem Statement

Nowadays everyone possesses one or more email accounts for digital communication. You may have observed that your mailbox classifies your relevant emails as primary emails and other irrelevant emails as spam.

**Spam** emails are junk emails or unrequired emails. They may consist of advertisements, updated, and unwanted messages which are sent to the receivers without their permission. Hence, spam detection is one of the important problem statement in email and messaging servicing.

In this project, you will create a model to classify the emails as **spam** or **not spam** using Logistic Regression.

---

### List of Activities

**Activity 1:** Analysing the Dataset

**Activity 2:** Train-Test Split

**Activity 3:** Normalisation of the Features

**Activity 4:** Logistic Regression - Model Training

**Activity 5:** Logistic Regression - Model Prediction and Evaluation

---

#### Activity 1:  Analysing the Dataset

Create a Pandas DataFrame for **Spambase** dataset using the below link. This dataset consists of the following 58 columns. Most of the columns represent frequencies of a particular word or character in the email:


|Column #|Attribute|Description|
|-|-|-|
|0 - 47|word_freq_WORD|The first 48 columns are the percentage|
|||of the frequencies of the particular word one column each|
||||
|48 - 53|word_freq_CHAR|The next 6 columns are the percentage of the frequencies of the|
|||particular special character like semi-colon (;), exclamation (!) one column each|
||||
|54|capital_run_length_average|average length of uninterrupted sequences of capital letters|
||||
|55|capital_run_length_longest|length of longest uninterrupted sequence of capital letters|
||||
|56|capital_run_length_total|sum of the length of uninterrupted sequences of capital letters|
||||
|57|email_type|denotes whether the email is spam (1) or not (0)|



 -  **Dataset Link:** https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/spambase.csv
   
- **Source:** UCI Library https://archive.ics.uci.edu/ml/datasets/Spambase






Print the first five rows of the dataset. Check for null values and treat them accordingly (if any).
"""

# Import modules
import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
# Load the dataset
df = pd.read_csv("https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/spambase.csv")
# Print the first five rows of the DataFrame
df.head()

"""Rename the last column of the DataFrame as target."""

# Rename the last column as 'target'
df['target'] = df['1']
df.head()

"""Print the information of the DataFrame to verify the above update."""

# Print the dataset information
print(f"{df.info()}")

print(f"{df.isnull().sum()}")

"""**Q:** Are there any missing values?

**A:** No

---

#### Activity 2: Train-Test Split

You have to determine the effect of all the features on the 'target' variable. Thus, every column other than the `target` is the feature variable and `target` column is the target variable.

**Steps:**

1. Create a list of all the features.

2. Split the "DataFrame" into features and target arrays using the features list.

3. Split the dataset into a training set and test set such that the training set contains 70% of the instances and the remaining instances will become the test set.

4. Reshape the target variable arrays into two-dimensional arrays by using `reshape(-1, 1)` function of the `numpy` module.
"""

# Split the DataFrame into the train and test sets.
# Import the module
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
features = list(df.columns[:-1])
# Create a features list
features = list(df.columns[:-1])

# Split the DataFrame into the train and test sets such that test set has 30% of the values.
X = df[features]
y = df['target']
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.33,random_state = 42)
# Reshape target arrays to 2-dimensional array.
y_train_reshape = y_train.values.reshape(-1,1)
y_test_reshape = y_test.values.reshape(-1,1)

"""----

#### Activity 3: Normalisation of the Features

Get a descriptive analysis of the feature set and decide whether any normalisation is needed.

Describe the features for training data.
"""

# Get the descriptive statistics for 'X_train'.
X_train.describe()

"""Describe the features for the testing data."""

# Get the descriptive statistics for 'X_test'.
X_test.describe()

"""**Q:** Does the data needs normalisation? Why?

**A:**  Yes, the data needs normalisation as the range of all the columns are different

If the answer to the above question is **yes**, Normalise the data by calculating their $Z$-scores (or standard scaler) in the following code sections.

Define the Standard Normalisation function.
"""

# Define the 'standard_scalar()' function for calculating Z-scores
def standard_scalar(series) :
    return (series - series.mean())/series.std()

"""**Hint**
$Z$-score for each value can be calculated by the following expression:

$$Z = \frac{X - \mu}{\sigma}$$

Where,


- $X$ is an observation

- $\mu$ is the population mean

- $\sigma$ is the population standard deviation

Apply the normalisation function to the features of the training data.
"""

# Apply the 'standard_scalar()' on X_train using apply() function and get the descriptive statistics of the normalised X_train
X_train = X_train.apply(standard_scalar, axis = 1)
X_train.describe()

"""Apply the normalisation function to the features of the test data."""

# Apply the 'standard_scalar()' on X_test and get the descriptive statistics of the normalised X_test
X_test = X_test.apply(standard_scalar, axis=1)
X_test.describe()

"""---

#### Activity 4: Logistic Regression - Model Training

Implement Logistic Regression Classification using `sklearn` module to estimate the values of $\beta$ coefficients in the following way:

1. Deploy the model by importing the `LogisticRegression` class and create an object of this class.
2. Call the `fit()` function on the Logistic Regression object and print score using the `score()` function.
3. Print the $\beta$ coefficient values.
"""

# Deploy the 'LogisticRegression' model using the 'fit()' function.
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
log = LogisticRegression()
log.fit(X_train, y_train_reshape)
log.score(X_train, y_train_reshape)

"""Get the beta coefficients for the features using the model object trained in the above code."""

# Print the beta coefficient values
def decision_boundary(X, y) :
  logistic_reg = LogisticRegression(random_state=0).fit(X, y)
  coef_list = list(logistic_reg.intercept_) + list(logistic_reg.coef_[0])
  return coef_list

coef_list = decision_boundary(X_train, y_train_reshape)
for i in range(len(coef_list)) :
  print(f'Beta {i} = {coef_list[i] : .4f}')

"""----

#### Activity 5: Logistic Regression - Model Prediction and Evaluation

Predict the values for both training and test sets by calling the `predict()` function on the Logistic Regression object.
"""

# Make predictions on the test dataset by using the 'predict()' function.
y_test_pred = log.predict(X_test)
y_train_pred = log.predict(X_train)

"""Also, display the confusion matrix."""

# Display the results of confusion_matrix
print(confusion_matrix(y_test, y_test_pred))
print('-'*50)
print(confusion_matrix(y_train, y_train_pred))

"""**Q:** What is the positive outcome out of both the labels?

**A:** 80 & 132 are `False Positive` and 96 & 155 are `False Negatives` .

**Q:** Write the count of True Positives and True Negatives?

**A:** 537 & 1024 are `True Positive` and 805 & 1771 are `True Negatives`.

Print the classification report values to evaluate the accuracy of your model.
"""

# Display the results of classification_report
print(classification_report(y_train, y_train_pred))
print(classification_report(y_test, y_test_pred))

"""**Q** Write the f1-score of both labels?

**A:** The `f1-score` of both labels are `0.93 & 0.88` and  `0.90 & 0.86` .

-----

### Submitting the Project

1. After finishing the project, click on the **Share** button on the top right corner of the notebook. A new dialog box will appear.

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/2_share_button.png' width=500>

2. In the dialog box, make sure that '**Anyone on the Internet with this link can view**' option is selected and then click on the **Copy link** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/3_copy_link.png' width=500>

3. The link of the duplicate copy (named as **YYYY-MM-DD_StudentName_Project77**) of the notebook will get copied.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/4_copy_link_confirmation.png' width=500>

4. Go to your dashboard and click on the **My Projects** option.
   
   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/5_student_dashboard.png' width=800>

  <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/6_my_projects.png' width=800>

5. Click on the **View Project** button for the project you want to submit.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/7_view_project.png' width=800>

6. Click on the **Submit Project Here** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/8_submit_project.png' width=800>

7. Paste the link to the project file named as **YYYY-MM-DD_StudentName_Project77** in the URL box and then click on the **Submit** button.

   <img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/project-share-images/9_enter_project_url.png' width=800>

---
"""